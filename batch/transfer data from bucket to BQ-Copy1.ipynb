{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b57225c-a240-46ed-8909-719d6b68ae49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- ID: string (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: string (nullable = true)\n",
      " |-- Domestic: string (nullable = true)\n",
      " |-- Beat: string (nullable = true)\n",
      " |-- District: string (nullable = true)\n",
      " |-- Ward: string (nullable = true)\n",
      " |-- Community Area: string (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: string (nullable = true)\n",
      " |-- Y Coordinate: string (nullable = true)\n",
      " |-- Year: string (nullable = true)\n",
      " |-- Updated On: string (nullable = true)\n",
      " |-- Latitude: string (nullable = true)\n",
      " |-- Longitude: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "sparkConf = SparkConf()\n",
    "sparkConf.setMaster(\"spark://spark-master:7077\")\n",
    "sparkConf.setAppName(\"GCSExample\")\n",
    "sparkConf.set(\"spark.driver.memory\", \"2g\")\n",
    "sparkConf.set(\"spark.executor.cores\", \"1\")\n",
    "sparkConf.set(\"spark.driver.cores\", \"1\")\n",
    "\n",
    "# create the spark session, which is the entry point to Spark SQL engine.\n",
    "spark = SparkSession.builder.config(conf=sparkConf).getOrCreate()\n",
    "\n",
    "#### read data from google bucket\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "#  Google Storage File Path\n",
    "gsc_file_path = 'gs://group6_chicagocrime/chicago_crimes2.csv'  #  use your gcp bucket name. Also upload sales.csv first\n",
    "\n",
    "# Create data frame\n",
    "df = spark.read.format(\"csv\").option(\"header\", \"true\") \\\n",
    "            .load(gsc_file_path)\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc131d2-6745-41a6-9b08-28e1b054a7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requiered functions\n",
    "\n",
    "from pyspark.sql.functions import  expr , col , count , when , isnan\n",
    "from pyspark.sql.functions import avg,sum,min,max,row_number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666cd9d4-1e82-459b-90b2-785a5bec4614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|Community Area|\n",
      "+--------------+\n",
      "|             0|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## clean data using filter function to remove Null values. \n",
    "\n",
    "df_clean = df.filter( col(\"Community Area\").isNotNull())\n",
    "df_clean.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in ['Community Area']] # check for absence of any Null value in Community area Column\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5886ab44-0476-428b-bf6e-cbba4bd4e819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|Community Area|count|\n",
      "+--------------+-----+\n",
      "|           9.0|  258|\n",
      "|          47.0|  389|\n",
      "|          12.0|  450|\n",
      "|          55.0|  516|\n",
      "|          18.0|  587|\n",
      "|          74.0|  619|\n",
      "|          36.0|  636|\n",
      "|          37.0|  843|\n",
      "|          13.0|  844|\n",
      "|          64.0|  942|\n",
      "|          72.0|  991|\n",
      "|          57.0|  999|\n",
      "|          62.0| 1037|\n",
      "|          50.0| 1049|\n",
      "|          59.0| 1083|\n",
      "|          34.0| 1085|\n",
      "|          11.0| 1157|\n",
      "|          54.0| 1189|\n",
      "|          10.0| 1279|\n",
      "|          52.0| 1319|\n",
      "+--------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------+-----+-------------------+\n",
      "|Community Area|count|  percentage(count)|\n",
      "+--------------+-----+-------------------+\n",
      "|           1.0| 3592| 1.3585219644106579|\n",
      "|          75.0| 2088|   0.78969762296477|\n",
      "|          50.0| 1049|0.39673984985155347|\n",
      "|          22.0| 4809| 1.8188007034662734|\n",
      "|          65.0| 2056| 0.7775949774020915|\n",
      "|          38.0| 3159|  1.194758041640665|\n",
      "|          66.0| 6228|  2.355477392636297|\n",
      "|          20.0| 1735| 0.6561903141014731|\n",
      "|          15.0| 3454|  1.306329305421607|\n",
      "|          45.0| 1391| 0.5260868743026795|\n",
      "|          67.0| 7548|  2.854711522096783|\n",
      "|          47.0|  389| 0.1471227851213101|\n",
      "|          63.0| 2367| 0.8952175639643728|\n",
      "|          44.0| 6051| 2.2885346343677315|\n",
      "|          69.0| 6784| 2.5657608592878347|\n",
      "|          25.0|17414|  6.586108432140088|\n",
      "|          26.0| 6038| 2.2836179346078933|\n",
      "|          72.0|  991| 0.3748038047691987|\n",
      "|          59.0| 1083| 0.4095989107618994|\n",
      "|          17.0| 1660| 0.6278247385639454|\n",
      "+--------------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "264405\n"
     ]
    }
   ],
   "source": [
    "#get the result for bellow question:\n",
    "#1- percentage of arrested criminals in each community area \n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "NumberCrimeInArea =df.groupBy(\"Community Area\").count()\n",
    "NumberCrimeInArea.orderBy(expr(\"count\")).show()\n",
    "\n",
    "# calculate sum of all crimes in all areas \n",
    "sumAr = NumberCrimeInArea.select(sum(\"count\"))\n",
    "# extract the integer to use in the function \n",
    "sumArrested = sumAr.first()['sum(count)']\n",
    "\n",
    "# define the function to calculate the percentage of Arreste criminals in each Community Area\n",
    "def percentage(value):\n",
    "    return ((value/sumArrested) * 100)\n",
    "\n",
    "# register the function\n",
    "percentageudf = udf(percentage)\n",
    "\n",
    "# use the function with SQL quries to have the column of percentage of arrested criminals in each Community Areas \n",
    "NumberCrimeInAreas = NumberCrimeInArea.select(col(\"Community Area\"),col(\"count\"), percentageudf(col(\"count\")))\n",
    "NumberCrimeInAreas.show()\n",
    "print(sumArrested)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c481a730-61a5-4883-8cce-257090e20133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the NumberCrimeInAreas table in the BigQuery \n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used by the connector.\n",
    "bucket = \"group6_chicagocrime\"  #  bucket for the assignment\n",
    "spark.conf.set('temporaryGcsBucket', bucket)\n",
    "\n",
    "# Setup hadoop fs configuration for schema gs://\n",
    "conf = spark.sparkContext._jsc.hadoopConfiguration()\n",
    "conf.set(\"fs.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystem\")\n",
    "conf.set(\"fs.AbstractFileSystem.gs.impl\", \"com.google.cloud.hadoop.fs.gcs.GoogleHadoopFS\")\n",
    "\n",
    "# Saving the data to BigQuery\n",
    "NumberCrimeInAreas.write.format('bigquery') \\\n",
    "  .option('table', 'datatengineering-group6.ChicagoCrime.NumberCrimeInAreas') \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c6c91a-a0ee-44c9-a31f-eb3b6ad2b67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------+\n",
      "|Community Area|       Primary Type|max(count)|\n",
      "+--------------+-------------------+----------+\n",
      "|           1.0|              ARSON|         4|\n",
      "|           1.0|            ASSAULT|       238|\n",
      "|           1.0|            BATTERY|       675|\n",
      "|           1.0|           BURGLARY|       166|\n",
      "|           1.0|CRIM SEXUAL ASSAULT|        27|\n",
      "+--------------+-------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------+---------------+\n",
      "|Community Area|max(max(count))|\n",
      "+--------------+---------------+\n",
      "|           1.0|            855|\n",
      "|          50.0|            233|\n",
      "|          75.0|            491|\n",
      "|          22.0|           1624|\n",
      "|          65.0|            655|\n",
      "|          38.0|            698|\n",
      "|          66.0|           1262|\n",
      "|          20.0|            329|\n",
      "|          15.0|            810|\n",
      "|          45.0|            274|\n",
      "+--------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "+---------+------------+----------+\n",
      "|Community|Primary Type|max(count)|\n",
      "+---------+------------+----------+\n",
      "|      1.0|       THEFT|       855|\n",
      "|     10.0|       THEFT|       323|\n",
      "|     11.0|       THEFT|       294|\n",
      "|     12.0|       THEFT|       125|\n",
      "|     13.0|       THEFT|       246|\n",
      "|     14.0|       THEFT|       550|\n",
      "|     15.0|       THEFT|       810|\n",
      "|     16.0|       THEFT|       763|\n",
      "|     17.0|       THEFT|       311|\n",
      "|     18.0|       THEFT|       122|\n",
      "|     19.0|     BATTERY|       977|\n",
      "|      2.0|       THEFT|       683|\n",
      "|     20.0|     BATTERY|       329|\n",
      "|     21.0|       THEFT|       636|\n",
      "|     22.0|       THEFT|      1624|\n",
      "|     23.0|     BATTERY|      1703|\n",
      "|     24.0|       THEFT|      2641|\n",
      "|     25.0|     BATTERY|      3564|\n",
      "|     26.0|   NARCOTICS|      2089|\n",
      "|     27.0|   NARCOTICS|      1499|\n",
      "|     28.0|       THEFT|      2701|\n",
      "|     29.0|     BATTERY|      1909|\n",
      "|      3.0|       THEFT|       886|\n",
      "|     30.0|     BATTERY|      1011|\n",
      "|     31.0|       THEFT|       541|\n",
      "|     32.0|       THEFT|      4049|\n",
      "|     33.0|       THEFT|       613|\n",
      "|     34.0|       THEFT|       240|\n",
      "|     35.0|       THEFT|       639|\n",
      "|     36.0|       THEFT|       140|\n",
      "|     37.0|     BATTERY|       169|\n",
      "|     38.0|       THEFT|       698|\n",
      "|     39.0|       THEFT|       307|\n",
      "|      4.0|       THEFT|       504|\n",
      "|     40.0|     BATTERY|       689|\n",
      "|     41.0|       THEFT|       487|\n",
      "|     42.0|     BATTERY|       813|\n",
      "|     43.0|     BATTERY|      2059|\n",
      "|     44.0|       THEFT|      1335|\n",
      "|     45.0|     BATTERY|       274|\n",
      "|     46.0|     BATTERY|      1178|\n",
      "|     47.0|     BATTERY|        69|\n",
      "|     48.0|       THEFT|       286|\n",
      "|     49.0|     BATTERY|      1435|\n",
      "|      5.0|       THEFT|       521|\n",
      "|     50.0|       THEFT|       233|\n",
      "|     51.0|       THEFT|       390|\n",
      "|     52.0|     BATTERY|       259|\n",
      "|     53.0|     BATTERY|       871|\n",
      "|     54.0|     BATTERY|       325|\n",
      "|     55.0|     BATTERY|       107|\n",
      "|     55.0|       THEFT|       107|\n",
      "|     56.0|       THEFT|       406|\n",
      "|     57.0|       THEFT|       221|\n",
      "|     58.0|     BATTERY|       549|\n",
      "|     59.0|       THEFT|       282|\n",
      "|      6.0|       THEFT|      2171|\n",
      "|     60.0|       THEFT|       373|\n",
      "|     61.0|     BATTERY|      1053|\n",
      "|     62.0|       THEFT|       232|\n",
      "|     63.0|     BATTERY|       453|\n",
      "|     64.0|       THEFT|       172|\n",
      "|     65.0|       THEFT|       655|\n",
      "|     66.0|     BATTERY|      1262|\n",
      "|     67.0|     BATTERY|      1674|\n",
      "|     68.0|     BATTERY|      1622|\n",
      "|     69.0|     BATTERY|      1610|\n",
      "|      7.0|       THEFT|      1755|\n",
      "|     70.0|       THEFT|       460|\n",
      "|     71.0|     BATTERY|      1680|\n",
      "|     72.0|       THEFT|       323|\n",
      "|     73.0|     BATTERY|       603|\n",
      "|     74.0|       THEFT|       158|\n",
      "|     75.0|       THEFT|       491|\n",
      "|     76.0|       THEFT|       517|\n",
      "|     77.0|       THEFT|       684|\n",
      "|      8.0|       THEFT|      4216|\n",
      "|      9.0|     BATTERY|        49|\n",
      "+---------+------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2- finding the most occurred crime in each area\n",
    "\n",
    "from pyspark.sql.functions import col, to_date\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import count\n",
    "\n",
    "\n",
    "windowSpec = Window\\\n",
    "  .partitionBy(\"Community Area\", \"Primary Type\")\\\n",
    "  .orderBy(desc(\"Primary Type\"))\\\n",
    "  .rowsBetween(Window.unboundedPreceding, Window.currentRow)\n",
    "\n",
    "dfWithcount1 = df_clean.withColumn(\"count\",count(\"Primary Type\").over(windowSpec))\n",
    "\n",
    "dfgrouped= dfWithcount1.groupBy(\"Community Area\", \"Primary Type\").agg(max(\"count\"))\n",
    "\n",
    "dfgrouped.show(5)\n",
    "#dfgrouped.show(10)\n",
    "df_gr=dfgrouped.groupBy(\"Community Area\").agg(max(\"max(count)\"))\n",
    "\n",
    "df_gr.show(10)\n",
    "\n",
    "df2 = dfgrouped.withColumnRenamed(\"Community Area\", \"Community\")\n",
    "featur = (df2[\"Community\"] == df_gr[\"Community Area\"]) & (df2[\"max(count)\"] == df_gr[\"max(max(count))\"])\n",
    "df2.join(df_gr,featur ).drop(\"Community Area\",\"max(max(count))\").show(100)\n",
    "MaxCrimeInArea= df2.join(df_gr,featur ).drop(\"Community Area\",\"max(max(count))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "416f8be3-0b7c-40f9-ac22-54ee35c7a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Saving the data to BigQuery\n",
    "MaxCrimeInArea.write.format('bigquery') \\\n",
    "  .option('table', 'datatengineering-group6.ChicagoCrime.MaxCrimeInArea') \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7251e20c-569d-4dd8-9355-5d6ab6989dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|   avg(CountCrime)|\n",
      "+------------------+\n",
      "|3433.8311688311687|\n",
      "+------------------+\n",
      "\n",
      "3433.8311688311687\n",
      "+--------------+----------+\n",
      "|Community Area|CountCrime|\n",
      "+--------------+----------+\n",
      "|           1.0|      3592|\n",
      "|          22.0|      4809|\n",
      "|          66.0|      6228|\n",
      "|          15.0|      3454|\n",
      "|          67.0|      7548|\n",
      "|          44.0|      6051|\n",
      "|          69.0|      6784|\n",
      "|          25.0|     17414|\n",
      "|          26.0|      6038|\n",
      "|          29.0|      8433|\n",
      "|          71.0|      7858|\n",
      "|          46.0|      5093|\n",
      "|          19.0|      4846|\n",
      "|          23.0|      8203|\n",
      "|           6.0|      5590|\n",
      "|          32.0|      7596|\n",
      "|           7.0|      3764|\n",
      "|          27.0|      5463|\n",
      "|          68.0|      7258|\n",
      "|          24.0|      7087|\n",
      "+--------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##3-the area with the number of crimes more than average\n",
    " \n",
    "from pyspark.sql.functions import sum, sum_distinct, mean\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_1 = df_clean.groupby(\"Community Area\").agg(count(\"Primary Type\"))\n",
    "df_3 = df_1.withColumnRenamed(\"count(Primary Type)\", \"CountCrime\")\n",
    "\n",
    "df_3\n",
    "\n",
    "TotalCrime=df_3.select(\n",
    "    sum(\"CountCrime\").alias(\"TotalCrime\"))\n",
    "#TotalCrime.select(expr(\"mean(count('Primary Type'))\").alias(\"mean_TotalCrime\")).show()\n",
    "average = df_3.select(mean(\"CountCrime\"))\n",
    "average.show()\n",
    "averageint = average.first()['avg(CountCrime)']\n",
    "print(averageint)\n",
    "\n",
    "\n",
    "\n",
    "df_final = df_3.where(df_3.CountCrime >= averageint)\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78b86e12-447d-419a-9be5-57ac3a040dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### write data on BIGQUERY\n",
    "\n",
    "# Saving the data to BigQuery\n",
    "df_final.write.format('bigquery') \\\n",
    "  .option('table', 'datatengineering-group6.ChicagoCrime.AreaWithCrimeMoreAvg') \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a945556b-04fa-4ef2-a1f8-821194048e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|        Primary Type| max|\n",
      "+--------------------+----+\n",
      "|               THEFT|4216|\n",
      "|             BATTERY|3564|\n",
      "|           NARCOTICS|3277|\n",
      "|     CRIMINAL DAMAGE|1542|\n",
      "|       OTHER OFFENSE|1251|\n",
      "|  DECEPTIVE PRACTICE|1214|\n",
      "|             ASSAULT|1096|\n",
      "|             ROBBERY| 771|\n",
      "|            BURGLARY| 745|\n",
      "| MOTOR VEHICLE THEFT| 655|\n",
      "|   CRIMINAL TRESPASS| 354|\n",
      "|        PROSTITUTION| 324|\n",
      "|   WEAPONS VIOLATION| 266|\n",
      "|PUBLIC PEACE VIOL...| 170|\n",
      "|OFFENSE INVOLVING...| 157|\n",
      "|INTERFERENCE WITH...| 150|\n",
      "| CRIM SEXUAL ASSAULT| 103|\n",
      "|            HOMICIDE|  50|\n",
      "|            GAMBLING|  46|\n",
      "|         SEX OFFENSE|  43|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## 4- which crimes are more likely to have criminals arrested\n",
    "\n",
    "from pyspark.sql.functions import col,avg,sum,min,max,row_number , desc\n",
    "\n",
    "dfAREST=dfWithcount1.select(\"Primary Type\", \"count\")\n",
    "\n",
    "windowSpecAgg  = Window.partitionBy(\"Primary Type\").orderBy(col(\"count\").desc())\n",
    "\n",
    "dfARESTs = dfAREST.withColumn(\"row\",row_number().over(windowSpecAgg)) \\\n",
    "        .withColumn(\"max\", max(col(\"count\")).over(windowSpecAgg))\\\n",
    "        .where(col(\"row\")== 1).orderBy(desc(\"max\")).select(\"Primary Type\",\"max\")\n",
    "dfARESTs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf3b3280-35c4-4b65-b4c0-3a0e55ea49a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### write data on BIGQUERY\n",
    "\n",
    "# Saving the data to BigQuery\n",
    "dfARESTs.write.format('bigquery') \\\n",
    "  .option('table', 'datatengineering-group6.ChicagoCrime.ArestedCriminalsPerCrime') \\\n",
    "  .mode(\"overwrite\") \\\n",
    "  .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca2b50f1-1bfc-4215-9688-5806aedf5895",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8002524e-a8ea-44ee-ba57-04ca7669faaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ca3967508393c830e5fdf827e244c60a1e86d5fcaf2e086715c4929113c1ab3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
